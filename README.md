üöó Vehicle Data MLOps Project: Quick Start GuideThis project implements an end-to-end Machine Learning Operations (MLOps) pipeline for vehicle data, covering everything from database connection to continuous deployment (CI/CD) on AWS.1. üêç Local Setup & EnvironmentStepActionNotesProject SetupExecute template.pyCreates the project boilerplate structure.Local PackagesConfigure setup.py & pyproject.tomlEnables module imports across the project.Virtual Environmentconda create -n vehicle python=3.10 -y $\rightarrow$ conda activate vehicle $\rightarrow$ pip install -r requirements.txtSets up and activates the dedicated Python environment.UtilitiesImplement Logging and Exception HandlingTest these utilities using demo.py.2. üíæ MongoDB Atlas IntegrationThis project uses MongoDB Atlas as the primary data source.Atlas Setup: Sign up, create a project, and deploy an M0 Cluster.Access Configuration: Create a DB user and set Network Access to 0.0.0.0/0.Connection String: Copy the connection string (Python driver).Data Ingestion Demo: Create notebook/mongoDB_demo.ipynb and push the initial dataset to your Atlas cluster.Set Environment Variable: Export your MongoDB connection URL.Bash: export MONGODB_URL="..."Powershell: $env:MONGODB_URL = "..."3. ‚öôÔ∏è MLOps Pipeline ComponentsThe core ML pipeline is built using modular components:ComponentImplementation FocusPre-requisitesData IngestionConnects to MongoDB, fetches data, and transforms it to a DataFrame.Variables in constants.__init__.py, DB connection in mongo_db_connections.py.Data ValidationChecks data quality against schema defined in config.schema.yaml.Complete utils.main_utils.py and config.schema.yaml.Data TransformationPreprocesses data (e.g., scaling, encoding).Implement classes in entity/estimator.py.Model TrainerTrains and saves the best machine learning model.Update entity/estimator.py.Model Evaluation & PusherCompares current model with the production model in S3 and pushes the best one.Requires AWS setup (Section 4).4. ‚òÅÔ∏è AWS S3 Setup (Model Registry)AWS is used for model storage and deployment infrastructure.IAM User (firstproj): Create an IAM user with AdministratorAccess and generate an Access Key ID and Secret Access Key.Environment Variables: Set the AWS credentials locally (e.g., export AWS_ACCESS_KEY_ID="...").S3 Bucket: Create a public-read S3 bucket named my-model-mlopsproj in us-east-1 to act as the Model Registry.Code Integration: Add code to src.configuration.aws_connection.py and src.aws_storage to handle S3 interactions.5. üåê Web Application & PredictionPrediction Pipeline: Set up the logic for real-time inference.Web App: Implement app.py using a framework (like Flask/Streamlit) and add static and template folders for the front end.6. üîÅ CI/CD with GitHub Actions & EC2Automate the build, push, and deployment process.Docker Setup: Create Dockerfile and .dockerignore.ECR Repository: Create an ECR repo (vehicleproj) to store Docker images.EC2 Runner: Launch an Ubuntu T2 Medium instance on AWS.Install Docker on the EC2 machine.Configure the EC2 instance as a self-hosted runner for your GitHub project.GitHub Secrets: Set the following repository secrets:AWS_ACCESS_KEY_ID (for CI/CD user, e.g., usvisa-user)AWS_SECRET_ACCESS_KEYAWS_DEFAULT_REGIONECR_REPODeployment: The aws.yaml workflow will trigger on push.Launch: Update the EC2 Security Group to open port 5080. Access the application via: http://<EC2-Public-IP>:5080.Model training can also be triggered at the /training route.
